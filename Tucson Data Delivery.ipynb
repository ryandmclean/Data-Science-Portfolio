{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucson Monthly Reports\n",
    "- https://jira.abcmouse.com/browse/PDA-6867\n",
    "- https://jira.abcmouse.com/browse/PDA-7082\n",
    "\n",
    "The purpose of this report is to provide monthly usage data for their Native American Student population. The first ticket outlines that they need usage (minutes played), while the second determines that they need skills mastered. \n",
    "\n",
    "The cadence of this report is to provide data for each month, from July 2023 until May 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get the data \n",
    "query = \"\"\"\n",
    "with base as (\n",
    "   -- Get rostering information based on what is active on the last day of the month\n",
    "SELECT\n",
    "    AOFL_PRODUCT,\n",
    "    STUDENT_ID,\n",
    "    ORGANIZATION_ID,\n",
    "    ORGANIZATION_NAME,\n",
    "    MONTH as final_month,\n",
    "    DATE as final_day,\n",
    "    -- Concatenate together values from different active grades, schools, classrooms, and teachers\n",
    "    LISTAGG(DISTINCT GRADE, '; ') WITHIN GROUP (ORDER BY GRADE ASC) AS GRADE, \n",
    "    LISTAGG(DISTINCT SCHOOL_NAME, '; ') WITHIN GROUP (ORDER BY SCHOOL_NAME ASC) AS SCHOOL_NAME, \n",
    "    LISTAGG(DISTINCT CLASSROOM_NAME, '; ') WITHIN GROUP (ORDER BY CLASSROOM_NAME ASC) AS CLASSROOM_NAME,\n",
    "    LISTAGG(DISTINCT TEACHER_ID, '; ') WITHIN GROUP (ORDER BY TEACHER_ID ASC) AS teachers\n",
    "FROM SCHOOLS_DW.DM.MASTERY_LICENSED_ACTIVE_DAILY_SNAPSHOT\n",
    "WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "  -- AND DATE = DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "  AND DATE = DATEADD(day, -1, CURRENT_DATE()) // Defined in the scope of the project\n",
    "  AND IS_LICENSED_SCHOOL = TRUE\n",
    "  AND IS_LICENSED_CLASSROOM = TRUE\n",
    "  AND STUDENT_GROUP_LINK_STATUS = 'active'\n",
    "  AND IS_LICENSED_STUDENT = TRUE\n",
    "  AND (DATE = LAST_DAY(DATE) OR DATE = DATEADD(day, -1, CURRENT_DATE()))-- Retrieves the last day of the month for the given DATE\n",
    "GROUP BY 1, 2, 3, 4, 5, 6\n",
    "), distinct_daily_usage as (\n",
    "// Since every line has multiple rows for a given day based on rostering information\n",
    "// I need to deduplicate the usage before aggregating. \n",
    "SELECT DISTINCT\n",
    "    AOFL_PRODUCT,\n",
    "    STUDENT_ID,\n",
    "    DATE,\n",
    "    WEEK,\n",
    "    MONTH,\n",
    "    time_spend,\n",
    "    HAS_PLACEMENT\n",
    "FROM SCHOOLS_DW.DM.MASTERY_LICENSED_ACTIVE_DAILY_SNAPSHOT \n",
    "WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "-- AND DATE BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "AND DATE BETWEEN '2023-07-01' AND DATEADD(day, -1, CURRENT_DATE()) // Yesterday for QA\n",
    "), monthly_usage as (\n",
    " SELECT \n",
    "    AOFL_PRODUCT,\n",
    "    STUDENT_ID,\n",
    "    MONTH,\n",
    "    sum(time_spend) / 60 as monthly_usage_minutes,\n",
    "    MAX(HAS_PLACEMENT) as HAS_PLACEMENT,\n",
    "    MAX(iff(time_spend > 0, DATE,null)) as max_login_date,\n",
    "    MIN(iff(time_spend > 0, DATE,null)) as MIN_login_date,\n",
    "    ARRAY_DISTINCT(ARRAY_AGG(DISTINCT IFF(time_spend > 0, WEEK, NULL))) as weeks_aggregated\n",
    "FROM distinct_daily_usage\n",
    "GROUP BY 1,2,3\n",
    "), total_usage as (\n",
    "SELECT \n",
    "    AOFL_PRODUCT,\n",
    "    STUDENT_ID,\n",
    "    NULLIF(sum(monthly_usage_minutes), 0) as total_usage_minutes,\n",
    "    avg(iff(monthly_usage_minutes > 0,monthly_usage_minutes,null)) as average_usage_minutes_per_month,\n",
    "    median(iff(monthly_usage_minutes > 0,monthly_usage_minutes,null)) as median_usage_minutes_per_month,\n",
    "    NULLIF(array_size(array_distinct(array_flatten(array_agg(weeks_aggregated)))),0) AS total_active_weeks,\n",
    "    array_distinct(array_flatten(array_agg(weeks_aggregated))) as weeks_aggregated,\n",
    "    MAX(HAS_PLACEMENT) as HAS_PLACEMENT,\n",
    "    MAX(iff(monthly_usage_minutes > 0, max_login_date,null)) as max_login_date,\n",
    "    MIN(iff(monthly_usage_minutes > 0, min_login_date,null)) as min_login_date\n",
    "FROM monthly_usage\n",
    "GROUP BY 1,2\n",
    "), mra_monthly_skills as (\n",
    "SELECT \n",
    "    'my_reading_academy' as AOFL_PRODUCT,\n",
    "    USER_ID,\n",
    "    DATE_TRUNC('month', ETL_TIMESTAMP) AS MONTH,\n",
    "    SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED'), 1, 0)) AS COMPLETED_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'BYPASSED', 1, 0)) AS BYPASSED_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'IN_PROGRESS', 1, 0)) AS IN_PROGRESS_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'STRUGGLING', 1, 0)) AS STRUGGLING_SKILLS,\n",
    "    SUM(SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED', 'BYPASSED'), 1, 0))) \n",
    "        OVER (PARTITION BY USER_ID) AS TOTAL_COMPLETED_BYPASSED,\n",
    "    SUM(SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED'), 1, 0))) \n",
    "        OVER (PARTITION BY USER_ID) AS TOTAL_COMPLETED\n",
    "    FROM mra_dw.dm.mra_user_skill_prog \n",
    "    -- WHERE ETL_TIMESTAMP BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "    WHERE TO_DATE(ETL_TIMESTAMP) BETWEEN '2023-07-01' AND DATEADD(day, -1, CURRENT_DATE()) // Yesterday for QA\n",
    "    GROUP BY 1,2,3\n",
    "),\n",
    "mma_monthly_skills as (\n",
    "SELECT \n",
    "    'my_math_academy' AS AOFL_PRODUCT,\n",
    "    USER_ID,\n",
    "    DATE_TRUNC('month', ETL_TIMESTAMP) AS MONTH,\n",
    "    SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED'), 1, 0)) AS COMPLETED_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'BYPASSED', 1, 0)) AS BYPASSED_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'IN_PROGRESS', 1, 0)) AS IN_PROGRESS_SKILLS,\n",
    "    SUM(IFF(SKILL_STATUS = 'STRUGGLING', 1, 0)) AS STRUGGLING_SKILLS,\n",
    "    SUM(SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED', 'BYPASSED'), 1, 0))) \n",
    "        OVER (PARTITION BY USER_ID) AS TOTAL_COMPLETED_BYPASSED,\n",
    "    SUM(SUM(IFF(SKILL_STATUS IN ('MASTERED', 'COMPLETED'), 1, 0))) \n",
    "        OVER (PARTITION BY USER_ID) AS TOTAL_COMPLETED\n",
    "FROM mma_dw.dm.user_skill_prog\n",
    "-- WHERE ETL_TIMESTAMP BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "WHERE TO_DATE(ETL_TIMESTAMP) BETWEEN '2023-07-01' AND DATEADD(day, -1, CURRENT_DATE()) // Yesterday for QA\n",
    "GROUP BY 1,2,3\n",
    "), total_skills as (\n",
    "    SELECT a.*,\n",
    "    b.* EXCLUDE (AOFL_PRODUCT,AOFL_PRODUCT_ID)\n",
    "    FROM (SELECT * FROM mra_monthly_skills UNION ALL SELECT * FROM mma_monthly_skills) a\n",
    "    LEFT JOIN (SELECT DISTINCT AOFL_PRODUCT, AOFL_PRODUCT_ID,STUDENT_ID,STUDENT_ROOT_ID,STUDENT_ROSTER_ID,STUDENT_EXTERNAL_ID \n",
    "                FROM EMS_DW.DW.EMS_DIM_STUDENTS WHERE IS_CURRENT = TRUE) b \n",
    "                on a.AOFL_PRODUCT = b.AOFL_PRODUCT AND a.USER_ID = b.AOFL_PRODUCT_ID\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    a.* EXCLUDE (TEACHERS),\n",
    "    SPLIT_PART(TEACHERS, '; ', 1) AS TEACHER1,\n",
    "    SPLIT_PART(TEACHERS, '; ', 2) AS TEACHER2,\n",
    "    SPLIT_PART(TEACHERS, '; ', 3) AS TEACHER3,\n",
    "    CASE WHEN d.HAS_PLACEMENT = TRUE THEN 'YES'\n",
    "         WHEN d.total_usage_minutes > 0 THEN 'IN PROGRESS'\n",
    "         ELSE 'NO' END as PLACEMENT_STATUS,\n",
    "    b.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID,HAS_PLACEMENT,max_login_date,min_login_date, WEEKS_AGGREGATED),\n",
    "    c.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID,MONTH),\n",
    "    d.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID)\n",
    "FROM base a\n",
    "LEFT JOIN monthly_usage b USING (AOFL_PRODUCT,STUDENT_ID)\n",
    "LEFT JOIN total_skills c USING (AOFL_PRODUCT,STUDENT_ID,MONTH)\n",
    "LEFT JOIN total_usage d USING (AOFL_PRODUCT,STUDENT_ID)\n",
    "WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "-- AND b.MONTH BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "AND b.MONTH BETWEEN '2023-07-01' AND DATEADD(day, -1, CURRENT_DATE()) // Yesterday for QA\n",
    "-- AND a.STUDENT_ID = 1244188\n",
    "ORDER BY a.AOFL_PRODUCT, a.STUDENT_ID, b.MONTH;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters for the report\n",
    "We need to tell the code where to point for all of the filenames in this report. You will need 3\n",
    "1. Location of the PII data, provided by Tucson * \n",
    "2. Location of the usage data\n",
    "3. Export Location\n",
    "\n",
    "* Since this report isn't for all students, it is only for Tucson Native American students, we need a separate file to do the filtering. \n",
    "This file was provided by Tucson and has been manually edited to add in our internal ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your Excel file\n",
    "file_path_dimensions = 'Student PII.xlsx' # Location of the PII data, provided by Tucson\n",
    "file_path_usage = 'Tucson Full District Usage by Month 2024-03-26.csv' # Location of the usage data, just run and exported from Snowflake\n",
    "file_path_export = 'Tucson Native American Student Usage - 2024-03-26.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data files\n",
    "Using the file names provided above, import the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use the read_excel function to read the file into a DataFrame\n",
    "dtype_spec = { # Pull in the IDs as characters so they don't get corrupted. \n",
    "    'Perm ID' : 'str',\n",
    "    'Internal ID' : 'str',\n",
    "    'STUDENT_ID' : 'str'\n",
    "}\n",
    "df_pii = pd.read_excel(file_path_dimensions, engine='openpyxl',dtype=dtype_spec)\n",
    "df_usage = pd.read_csv(file_path_usage,dtype=dtype_spec)\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm successful import\n",
    "# df_usage.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the Usage and PII\n",
    "Join the two files together, with the PII on the left to filter for only Tucson Native American students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left = df_pii,right = df_usage, left_on = ['Internal ID'],right_on=['STUDENT_ID'])\n",
    "df['MONTHLY_SKILLS_MASTERED'] = df['COMPLETED_SKILLS'] + df['BYPASSED_SKILLS']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region join\n",
    "Since I want to keep the School in our system, instead of the school from the original file, I need to make sure that I have the correct region tied to every individual student. So, first, I will create a lookup table for the regions, and then join that back in so that the SCHOOL_NAME from Snowflake has the correct region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Johnson Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Lawrence 3-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Miller Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Rose K-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Roskruge Bilingual K-8 Magnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>White Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Borton Magnet Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Grijalva Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Arroyo Chico</td>\n",
       "      <td>Lineweaver Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Manzo Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Mary Belle McCorkle Academy of Excellence K-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Morgan Maxwell K-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>Myers/Ganoung Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>Naylor K-8 (with Roberts)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>Wheeler Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Arroyo Chico</td>\n",
       "      <td>Pueblo Gardens K-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Tolson Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Tully Elementary Magnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Arroyo Chico</td>\n",
       "      <td>Wright Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Robins K-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Arroyo Chico</td>\n",
       "      <td>Howell Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Silverbell</td>\n",
       "      <td>Vesey Elementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Total - 234 students</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              REGION_NAME                                    SCHOOL_NAME\n",
       "0              Silverbell                                Johnson Primary\n",
       "6              Silverbell                                   Lawrence 3-8\n",
       "7              Silverbell                              Miller Elementary\n",
       "14             Santa Cruz                                       Rose K-8\n",
       "26             Santa Cruz                  Roskruge Bilingual K-8 Magnet\n",
       "29             Silverbell                               White Elementary\n",
       "38             Santa Cruz                       Borton Magnet Elementary\n",
       "41             Santa Cruz                            Grijalva Elementary\n",
       "51           Arroyo Chico                          Lineweaver Elementary\n",
       "54             Silverbell                               Manzo Elementary\n",
       "56             Santa Cruz  Mary Belle McCorkle Academy of Excellence K-8\n",
       "60             Silverbell                             Morgan Maxwell K-8\n",
       "62                Arcadia                       Myers/Ganoung Elementary\n",
       "64                Arcadia                      Naylor K-8 (with Roberts)\n",
       "65                Arcadia                             Wheeler Elementary\n",
       "66           Arroyo Chico                             Pueblo Gardens K-8\n",
       "70             Silverbell                              Tolson Elementary\n",
       "73             Silverbell                        Tully Elementary Magnet\n",
       "79           Arroyo Chico                              Wright Elementary\n",
       "87             Silverbell                                     Robins K-8\n",
       "99           Arroyo Chico                              Howell Elementary\n",
       "100            Silverbell                               Vesey Elementary\n",
       "234                   NaN                                            NaN\n",
       "235  Total - 234 students                                            NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Region lookup\n",
    "df_region_lookup = df_pii[['Region','School']].drop_duplicates().rename(columns={'Region':'REGION_NAME','School':'SCHOOL_NAME'})\n",
    "\n",
    "df = pd.merge(left=df,right=df_region_lookup, on=['SCHOOL_NAME'])\n",
    "# df\n",
    "# df_region_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation 1\n",
    "1. Check for Duplicates from the join\n",
    "2. Ensure that the school names match up\n",
    "3. Check for where the Tucson Native American students are missing usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicates: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>School</th>\n",
       "      <th>Perm ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Notes</th>\n",
       "      <th>AOFL_PRODUCT</th>\n",
       "      <th>STUDENT_ID</th>\n",
       "      <th>ORGANIZATION_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Region, School, Perm ID, Last Name, First Name , Name, Grade, Gender, Internal ID, Notes, AOFL_PRODUCT, STUDENT_ID, ORGANIZATION_ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duplicate Instances of Perm ID\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "duplicates_df = df[df.duplicated(['AOFL_PRODUCT','Perm ID','MONTH'], keep=False)]  # keep=False to mark all duplicates as True\n",
    "print(f\"Total number of duplicates: {duplicates_df.shape[0]}\")\n",
    "duplicates_df.iloc[:, 0:13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where 'School' does not match 'SCHOOL_NAME', excluding known exceptions: 0 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>School</th>\n",
       "      <th>Perm ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>STUDENT_ID</th>\n",
       "      <th>AOFL_PRODUCT</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Region, School, Perm ID, Name, STUDENT_ID, AOFL_PRODUCT, MONTH, SCHOOL_NAME]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of exceptions with STUDENT_ID as keys and a description as values\n",
    "# These are students were rostering changes have been validated. \n",
    "exception_dict = {\n",
    "    '1063923': 'Rostering changed from Lawrence to Dietz in January, still shown in PII file as Lawrence',\n",
    "    '1063924': 'Rostering changed from Miller to Johnson in January',\n",
    "    '1108589': 'Rostering changed from Johnson to Virtual Academy in September, still shown in PII file as Johnson',\n",
    "    '1108673': 'Rostering changed from Roskruge to Mysers/Ganoung in November',\n",
    "    '1459436': 'Rostering changed from Vesey to Banks in November, still shown in PII file as Vesey',\n",
    "    '1459441': 'Rostering changed from Lawrence to Pueblo Gardens in November',\n",
    "    '1505434': 'Rostering changed from Morgan to Tucson virtual in October, still shown in PII file as Morgan',\n",
    "    '1543160': 'Rostering changed from Roskruge to Bienman virtual in January, still shown in PII file as Roskruge'\n",
    "}\n",
    "\n",
    "# Define a mask for rows where 'School' does not match 'SCHOOL_NAME'\n",
    "mismatch_mask = df['School'].str.strip() != df['SCHOOL_NAME'].str.strip()\n",
    "\n",
    "# Filter out the rows where STUDENT_ID is in the list of keys from the exception_dict\n",
    "filtered_mismatch_mask = mismatch_mask & (~df['STUDENT_ID'].isin(exception_dict.keys()))\n",
    "\n",
    "# Count mismatches after filtering out exceptions\n",
    "mismatches_count = filtered_mismatch_mask.sum()\n",
    "\n",
    "# Calculate the percentage of mismatches after filtering out exceptions\n",
    "total_rows = df.shape[0]\n",
    "mismatches_percentage = (mismatches_count / total_rows) * 100\n",
    "\n",
    "# Filter rows where 'School' and 'SCHOOL_NAME' do not match, excluding exceptions\n",
    "mismatches_df = df[filtered_mismatch_mask]\n",
    "\n",
    "# Print message including the percentage of affected rows\n",
    "print(f\"Number of rows where 'School' does not match 'SCHOOL_NAME', excluding known exceptions: {mismatches_count} ({mismatches_percentage:.2f}%)\")\n",
    "\n",
    "# Optionally, print specific columns of mismatches_df to inspect these cases\n",
    "mismatches_df[['Region', 'School', 'Perm ID', 'Name', 'STUDENT_ID', 'AOFL_PRODUCT', 'MONTH', 'SCHOOL_NAME']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of affected rows with 'TOTAL_USAGE_MINUTES' being zero or null: 141 out of 3290 total rows (4.29%)\n",
      "Number of unique affected students: 23 out of 215 total students (10.70%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your pandas DataFrame\n",
    "# Identify rows where 'TOTAL_USAGE_MINUTES' is zero or null\n",
    "zero_or_null_minutes_mask = df['TOTAL_USAGE_MINUTES'].isnull() | (df['TOTAL_USAGE_MINUTES'] == 0)\n",
    "\n",
    "# Count such rows\n",
    "zero_or_null_count = zero_or_null_minutes_mask.sum()\n",
    "\n",
    "# Filter rows meeting the condition\n",
    "zero_or_null_df = df[zero_or_null_minutes_mask]\n",
    "\n",
    "# Count the number of unique affected students\n",
    "unique_affected_students = zero_or_null_df['STUDENT_ID'].nunique()\n",
    "\n",
    "# Count the total number of unique students in the original DataFrame\n",
    "total_unique_students = df['STUDENT_ID'].nunique()\n",
    "\n",
    "# Calculate the percentage of unique affected students out of total unique students\n",
    "percentage_affected_students = (unique_affected_students / total_unique_students) * 100\n",
    "\n",
    "# Calculate the percentage of affected rows out of total rows\n",
    "total_rows = df.shape[0]\n",
    "percentage_affected_rows = (zero_or_null_count / total_rows) * 100\n",
    "\n",
    "# Print messages including the counts and percentages\n",
    "print(f\"Number of affected rows with 'TOTAL_USAGE_MINUTES' being zero or null: {zero_or_null_count} out of {total_rows} total rows ({percentage_affected_rows:.2f}%)\")\n",
    "print(f\"Number of unique affected students: {unique_affected_students} out of {total_unique_students} total students ({percentage_affected_students:.2f}%)\")\n",
    "\n",
    "# Optionally, print specific columns of zero_or_null_df to inspect these cases\n",
    "# zero_or_null_df[['Region', 'School', 'Perm ID', 'Name', 'STUDENT_ID', 'AOFL_PRODUCT', 'MONTH', 'SCHOOL_NAME', 'TOTAL_USAGE_MINUTES']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above data checks look good, then you can proceed with the export. \n",
    "\n",
    "## Pivot the data from long to wide, with columns for every month. \n",
    "The customer has requested that the data be in a format with the months as columns instead of rows. Meaning that we need to perform a pivot operation. However, before we are ready to do that, we need to handle an edge case. The edge case is when a student has usage in a given month, but not skills. That means that all of the dimensions related to skills are inaccurate for that month. To fix that, I created this compressed_df section where I compress all of the rows across the months for a student so that the dimensions would match up whether or not they had usage and skills in a given month. \n",
    "\n",
    "\n",
    "- A note here on which skills were chosen. The CS rep wanted all of the numbers to match educator center and within the report, meaning that we removed the bypassed skills and only reported on skills completed, using the same definition that educator center uses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean list of the dimensions needed for the final dataset. \n",
    "# Correctly renaming only the week columns, preserving key columns for the merge\n",
    "key_columns = ['REGION_NAME','SCHOOL_NAME','CLASSROOM_NAME', 'STUDENT_ID','USER_ID','Perm ID','Last Name', 'First Name ', 'Name',\n",
    "               'Grade', 'Gender','AOFL_PRODUCT', 'PLACEMENT_STATUS',\n",
    "               'TOTAL_ACTIVE_WEEKS','TOTAL_USAGE_MINUTES','TOTAL_COMPLETED',\n",
    "               'MIN_LOGIN_DATE','MAX_LOGIN_DATE'\n",
    "               ]\n",
    "# print(df[key_columns].dtypes)\n",
    "# Identify string and numeric columns\n",
    "string_columns = [col for col in key_columns if df[col].dtype == object]\n",
    "numeric_columns = [col for col in key_columns if col not in string_columns + ['STUDENT_ID', 'AOFL_PRODUCT']]\n",
    "\n",
    "# Aggregate string columns by distinct LISTAGG\n",
    "agg_string = {\n",
    "    col: lambda x: '; '.join(sorted(set([str(val) for val in x if pd.notnull(val)])))\n",
    "    for col in string_columns\n",
    "}\n",
    "\n",
    "# Aggregate numeric columns by average\n",
    "agg_numeric = {col: 'max' for col in numeric_columns}\n",
    "\n",
    "# Combine both aggregation dictionaries\n",
    "aggregations = {**agg_string, **agg_numeric}\n",
    "\n",
    "# Group by STUDENT_ID and AOFL_PRODUCT, then aggregate\n",
    "compressed_df = df.groupby(['STUDENT_ID', 'AOFL_PRODUCT'], as_index=False).agg(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for weekly usage minutes using simplified key columns\n",
    "pivot_usage = df.pivot_table(index=['STUDENT_ID', 'AOFL_PRODUCT'],\n",
    "                             columns='MONTH', \n",
    "                             values='MONTHLY_USAGE_MINUTES',\n",
    "                             aggfunc='sum',\n",
    "                             fill_value=0).reset_index()\n",
    "\n",
    "# Adjust column names for usage\n",
    "pivot_usage.columns = [f'Minutes_{pd.to_datetime(col).strftime(\"%b%Y\")}' if col not in ['STUDENT_ID', 'AOFL_PRODUCT'] and '-' in str(col) else col for col in pivot_usage.columns]\n",
    "\n",
    "# Pivot for skills data\n",
    "pivot_skills = df.pivot_table(index=['STUDENT_ID', 'AOFL_PRODUCT'],\n",
    "                              columns='MONTH', \n",
    "                              values='COMPLETED_SKILLS', # Use the column that does not contain bypassed skills\n",
    "                              aggfunc='sum',\n",
    "                              fill_value=0).reset_index()\n",
    "\n",
    "# Adjust column names for skills\n",
    "pivot_skills.columns = [f'SkillsCompleted_{pd.to_datetime(col).strftime(\"%b%Y\")}' if col not in ['STUDENT_ID', 'AOFL_PRODUCT'] and '-' in str(col) else col for col in pivot_skills.columns]\n",
    "# Merge the pivoted usage and skills tables on STUDENT_ID and AOFL_PRODUCT\n",
    "pivot_merged = pd.merge(pivot_usage, pivot_skills, \n",
    "                        on=['STUDENT_ID', 'AOFL_PRODUCT'], \n",
    "                        how='outer')\n",
    "\n",
    "# # Join the other dimensions back\n",
    "wide_df = pd.merge(compressed_df,pivot_merged, \n",
    "                   on=['STUDENT_ID', 'AOFL_PRODUCT'], \n",
    "                   how='left')\n",
    "\n",
    "# # Display the first few rows to verify the transformation\n",
    "# wide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation 2\n",
    "1. Check for Duplicates after the pivot\n",
    "2. Check for where the monthly skills don't match the total skills\n",
    "3. Check for where the monthly usage doesn't match the total usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicates: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>CLASSROOM_NAME</th>\n",
       "      <th>STUDENT_ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>Perm ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AOFL_PRODUCT</th>\n",
       "      <th>PLACEMENT_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [REGION_NAME, SCHOOL_NAME, CLASSROOM_NAME, STUDENT_ID, USER_ID, Perm ID, Last Name, First Name , Name, Grade, Gender, AOFL_PRODUCT, PLACEMENT_STATUS]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duplicate Instances of Perm ID\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "duplicates_df = wide_df[wide_df.duplicated(['AOFL_PRODUCT','Perm ID'], keep=False)]  # keep=False to mark all duplicates as True\n",
    "print(f\"Total number of duplicates: {duplicates_df.shape[0]}\")\n",
    "duplicates_df.iloc[:, 0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched rows: 0 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOFL_PRODUCT</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>CLASSROOM_NAME</th>\n",
       "      <th>Name</th>\n",
       "      <th>TOTAL_COMPLETED</th>\n",
       "      <th>SkillsCompleted_Jul2023</th>\n",
       "      <th>SkillsCompleted_Aug2023</th>\n",
       "      <th>SkillsCompleted_Sep2023</th>\n",
       "      <th>SkillsCompleted_Oct2023</th>\n",
       "      <th>SkillsCompleted_Nov2023</th>\n",
       "      <th>SkillsCompleted_Dec2023</th>\n",
       "      <th>SkillsCompleted_Jan2024</th>\n",
       "      <th>SkillsCompleted_Feb2024</th>\n",
       "      <th>SkillsCompleted_Mar2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AOFL_PRODUCT, SCHOOL_NAME, CLASSROOM_NAME, Name, TOTAL_COMPLETED, SkillsCompleted_Jul2023, SkillsCompleted_Aug2023, SkillsCompleted_Sep2023, SkillsCompleted_Oct2023, SkillsCompleted_Nov2023, SkillsCompleted_Dec2023, SkillsCompleted_Jan2024, SkillsCompleted_Feb2024, SkillsCompleted_Mar2024]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Identify all SkillsMastered columns\n",
    "skills_mastered_columns = [col for col in wide_df.columns if 'SkillsCompleted_' in col]\n",
    "\n",
    "# Create a new DataFrame for testing to avoid modifying wide_df\n",
    "test_df = wide_df.copy()\n",
    "test_df['TOTAL_COMPLETED'] = test_df['TOTAL_COMPLETED'].fillna(0) # Missing should be zero for this check. \n",
    "\n",
    "# Add a column for the sum of SkillsMastered columns\n",
    "test_df['SkillsCompleted_Sum'] = test_df[skills_mastered_columns].sum(axis=1)\n",
    "\n",
    "# Add a column to flag mismatches\n",
    "test_df['Mismatch'] = test_df['SkillsCompleted_Sum'] != test_df['TOTAL_COMPLETED']\n",
    "\n",
    "# Step 2: Count and report the number of mismatches\n",
    "mismatch_count = test_df['Mismatch'].sum()\n",
    "total_rows = len(test_df)\n",
    "mismatch_percentage = (mismatch_count / total_rows) * 100\n",
    "\n",
    "print(f\"Mismatched rows: {mismatch_count} ({mismatch_percentage:.2f}%)\")\n",
    "\n",
    "# Step 3: Print off the rows where the error is detected, including specific columns for clarity\n",
    "mismatched_rows = test_df[test_df['Mismatch']]\n",
    "columns_of_interest = ['AOFL_PRODUCT', 'SCHOOL_NAME', 'CLASSROOM_NAME', 'Name', 'TOTAL_COMPLETED'] + skills_mastered_columns\n",
    "mismatched_rows[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes mismatched rows (considering rounding): 0 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUDENT_ID</th>\n",
       "      <th>AOFL_PRODUCT</th>\n",
       "      <th>SCHOOL_NAME</th>\n",
       "      <th>CLASSROOM_NAME</th>\n",
       "      <th>Name</th>\n",
       "      <th>TOTAL_USAGE_MINUTES</th>\n",
       "      <th>Minutes_Sum</th>\n",
       "      <th>Minutes_Jul2023</th>\n",
       "      <th>Minutes_Aug2023</th>\n",
       "      <th>Minutes_Sep2023</th>\n",
       "      <th>Minutes_Oct2023</th>\n",
       "      <th>Minutes_Nov2023</th>\n",
       "      <th>Minutes_Dec2023</th>\n",
       "      <th>Minutes_Jan2024</th>\n",
       "      <th>Minutes_Feb2024</th>\n",
       "      <th>Minutes_Mar2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [STUDENT_ID, AOFL_PRODUCT, SCHOOL_NAME, CLASSROOM_NAME, Name, TOTAL_USAGE_MINUTES, Minutes_Sum, Minutes_Jul2023, Minutes_Aug2023, Minutes_Sep2023, Minutes_Oct2023, Minutes_Nov2023, Minutes_Dec2023, Minutes_Jan2024, Minutes_Feb2024, Minutes_Mar2024]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming wide_df is already defined\n",
    "\n",
    "# Create a new DataFrame for testing\n",
    "test_df_minutes = wide_df.copy()\n",
    "test_df_minutes['TOTAL_USAGE_MINUTES'] = test_df_minutes['TOTAL_USAGE_MINUTES'].fillna(0) # Missing should be zero for this check. \n",
    "\n",
    "# Step 1: Identify all Minutes_ columns\n",
    "minutes_columns = [col for col in wide_df.columns if col.startswith('Minutes_')]\n",
    "\n",
    "# Step 2: Sum these columns for each row, round the sum and TOTAL_USAGE_MINUTES to the third decimal place, then compare\n",
    "precision = 3\n",
    "test_df_minutes['Minutes_Sum'] = test_df_minutes[minutes_columns].sum(axis=1)\n",
    "test_df_minutes['Minutes_Mismatch'] = test_df_minutes['Minutes_Sum'].round(precision) != test_df_minutes['TOTAL_USAGE_MINUTES'].round(precision)\n",
    "\n",
    "# Step 3: Count and report the number of mismatches for minutes, considering the rounding\n",
    "minutes_mismatch_count = test_df_minutes['Minutes_Mismatch'].sum()\n",
    "total_rows = len(test_df_minutes)\n",
    "minutes_mismatch_percentage = (minutes_mismatch_count / total_rows) * 100\n",
    "\n",
    "print(f\"Minutes mismatched rows (considering rounding): {minutes_mismatch_count} ({minutes_mismatch_percentage:.2f}%)\")\n",
    "\n",
    "# Step 4: Print off the rows where the minutes error is detected, including the columns of interest\n",
    "minutes_mismatched_rows = test_df_minutes[test_df_minutes['Minutes_Mismatch']]\n",
    "columns_of_interest = ['STUDENT_ID','AOFL_PRODUCT', 'SCHOOL_NAME', 'CLASSROOM_NAME', 'Name', 'TOTAL_USAGE_MINUTES', 'Minutes_Sum'] + minutes_columns\n",
    "minutes_mismatched_rows[columns_of_interest]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Export\n",
    "Rename some of the dimensions from the file, clean up everything as it needs to be, and then export to CSV to be shared, via slack, with Sara Bleckinger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the renaming dictionary\n",
    "rename_dict = {\n",
    "    'REGION_NAME' : 'Region Name',\n",
    "    'SCHOOL_NAME' : 'School Name',\n",
    "    'CLASSROOM_NAME' : 'Classroom Name',\n",
    "    'AOFL_PRODUCT': 'AOFL Product',\n",
    "    'PLACEMENT_STATUS': 'Placement Status',\n",
    "    'TOTAL_USAGE_MINUTES': 'Total Minutes Year-to-Date',\n",
    "    'TOTAL_ACTIVE_WEEKS': 'Active Weeks Year-to-Date',\n",
    "    'TOTAL_COMPLETED_BYPASSED': 'Total Skills Mastered Year-to-Date',\n",
    "    'TOTAL_COMPLETED' : 'Total Skills Completed Year-to-Date',\n",
    "    'MIN_LOGIN_DATE' : 'First Login Date',\n",
    "    'MAX_LOGIN_DATE' : 'Latest Login Date'\n",
    "}\n",
    "\n",
    "# Rename columns in df using the rename_dict\n",
    "df_final = wide_df.rename(columns=rename_dict)\n",
    "df_final = df_final.drop(columns=['STUDENT_ID','USER_ID'])\n",
    "\n",
    "# Export df_final to a CSV file with the new filename\n",
    "sort_columns = ['Region Name','School Name','Classroom Name','AOFL Product','Last Name','First Name ']\n",
    "df_final.sort_values(by = sort_columns).to_csv(file_path_export, index=False)\n",
    "\n",
    "\n",
    "# df_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Query using the wrong skills table\n",
    "# query = '''\n",
    "# with base as (\n",
    "#    -- Get rostering information based on what is active on the last day of the month\n",
    "# SELECT\n",
    "#     AOFL_PRODUCT,\n",
    "#     STUDENT_ID,\n",
    "#     ORGANIZATION_ID,\n",
    "#     ORGANIZATION_NAME,\n",
    "#     MONTH,\n",
    "#     -- Concatenate together values from different active grades, schools, classrooms, and teachers\n",
    "#     LISTAGG(DISTINCT GRADE, '; ') WITHIN GROUP (ORDER BY GRADE ASC) AS GRADE, \n",
    "#     LISTAGG(DISTINCT SCHOOL_NAME, '; ') WITHIN GROUP (ORDER BY SCHOOL_NAME ASC) AS SCHOOL_NAME, \n",
    "#     LISTAGG(DISTINCT CLASSROOM_NAME, '; ') WITHIN GROUP (ORDER BY CLASSROOM_NAME ASC) AS CLASSROOM_NAME,\n",
    "#     LISTAGG(DISTINCT TEACHER_ID, '; ') WITHIN GROUP (ORDER BY TEACHER_ID ASC) AS teachers\n",
    "# FROM SCHOOLS_DW.DM.MASTERY_LICENSED_ACTIVE_DAILY_SNAPSHOT\n",
    "# WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "#   AND DATE BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "#   AND IS_LICENSED_SCHOOL = TRUE\n",
    "#   AND IS_LICENSED_CLASSROOM = TRUE\n",
    "#   AND STUDENT_GROUP_LINK_STATUS = 'active'\n",
    "#   AND IS_LICENSED_STUDENT = TRUE\n",
    "#   -- Teacher is not required, thus commented out\n",
    "#   -- AND IS_LICENSED_TEACHER = TRUE\n",
    "#   -- AND TEACHER_GROUP_STATUS = 'active'\n",
    "#   AND DATE = LAST_DAY(DATE) -- Retrieves the last day of the month for the given DATE\n",
    "# GROUP BY 1, 2, 3, 4, 5\n",
    "# ), distinct_daily_usage as (\n",
    "# // Since every line has multiple rows for a given day based on rostering information\n",
    "# // I need to deduplicate the usage before aggregating. \n",
    "# SELECT DISTINCT\n",
    "#     AOFL_PRODUCT,\n",
    "#     STUDENT_ID,\n",
    "#     DATE,\n",
    "#     WEEK,\n",
    "#     MONTH,\n",
    "#     time_spend,\n",
    "#     HAS_PLACEMENT\n",
    "# FROM SCHOOLS_DW.DM.MASTERY_LICENSED_ACTIVE_DAILY_SNAPSHOT \n",
    "# WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "# AND DATE BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "# ), monthly_usage as (\n",
    "#  SELECT \n",
    "#     AOFL_PRODUCT,\n",
    "#     STUDENT_ID,\n",
    "#     MONTH,\n",
    "#     sum(time_spend) / 60 as monthly_usage_minutes,\n",
    "#     MAX(HAS_PLACEMENT) as HAS_PLACEMENT,\n",
    "#     MAX(iff(time_spend > 0, DATE,null)) as max_login_date,\n",
    "#     MIN(iff(time_spend > 0, DATE,null)) as MIN_login_date,\n",
    "#     ARRAY_DISTINCT(ARRAY_AGG(DISTINCT IFF(time_spend > 0, WEEK, NULL))) as weeks_aggregated\n",
    "# FROM distinct_daily_usage\n",
    "# GROUP BY 1,2,3\n",
    "# ), total_usage as (\n",
    "# SELECT \n",
    "#     AOFL_PRODUCT,\n",
    "#     STUDENT_ID,\n",
    "#     NULLIF(sum(monthly_usage_minutes), 0) as total_usage_minutes,\n",
    "#     avg(iff(monthly_usage_minutes > 0,monthly_usage_minutes,null)) as average_usage_minutes_per_month,\n",
    "#     median(iff(monthly_usage_minutes > 0,monthly_usage_minutes,null)) as median_usage_minutes_per_month,\n",
    "#     NULLIF(array_size(array_distinct(array_flatten(array_agg(weeks_aggregated)))),0) AS total_active_weeks,\n",
    "#     array_distinct(array_flatten(array_agg(weeks_aggregated))) as weeks_aggregated,\n",
    "#     MAX(HAS_PLACEMENT) as HAS_PLACEMENT,\n",
    "#     MAX(iff(monthly_usage_minutes > 0, max_login_date,null)) as max_login_date,\n",
    "#     MIN(iff(monthly_usage_minutes > 0, min_login_date,null)) as min_login_date\n",
    "# FROM monthly_usage\n",
    "# GROUP BY 1,2\n",
    "# ), monthly_skills as (\n",
    "# SELECT \n",
    "#     AOFL_PRODUCT,\n",
    "#     MONTH,\n",
    "#     STUDENT_ID,\n",
    "#     NULLIF(array_size(array_distinct(array_flatten(array_agg(mastered_skills)))),0) as monthly_skills_mastered,\n",
    "#     array_distinct(array_flatten(array_agg(mastered_skills))) as mastered_skills\n",
    "# FROM SCHOOLS_DW.DM.MASTERY_SKILL_DAILY_SNAPSHOT\n",
    "# WHERE TERM_ID = 2\n",
    "# AND DATE BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "# GROUP BY 1,2,3\n",
    "# ),\n",
    "# total_skills as (\n",
    "# SELECT \n",
    "#     AOFL_PRODUCT,\n",
    "#     STUDENT_ID,\n",
    "#     NULLIF(array_size(array_distinct(array_flatten(array_agg(mastered_skills)))),0) as total_skills_mastered,\n",
    "#     avg(iff(monthly_skills_mastered > 0,monthly_skills_mastered,null)) as average_monthly_skills_per_month,\n",
    "#     median(iff(monthly_skills_mastered > 0,monthly_skills_mastered,null)) as median_monthly_skills_per_month -- CONFIRM AVERAGE OR MEDIAN\n",
    "# FROM monthly_skills\n",
    "# GROUP BY 1,2\n",
    "# )\n",
    "\n",
    "# SELECT \n",
    "#     a.* EXCLUDE (TEACHERS),\n",
    "#     SPLIT_PART(TEACHERS, '; ', 1) AS TEACHER1,\n",
    "#     SPLIT_PART(TEACHERS, '; ', 2) AS TEACHER2,\n",
    "#     SPLIT_PART(TEACHERS, '; ', 3) AS TEACHER3,\n",
    "#     CASE WHEN d.HAS_PLACEMENT = TRUE THEN 'YES'\n",
    "#          WHEN d.total_usage_minutes > 0 THEN 'IN PROGRESS'\n",
    "#          ELSE 'NO' END as PLACEMENT_STATUS,\n",
    "#     b.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID,MONTH,HAS_PLACEMENT,max_login_date,min_login_date, WEEKS_AGGREGATED),\n",
    "#     c.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID,MONTH,MASTERED_SKILLS),\n",
    "#     d.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID),\n",
    "#     e.* EXCLUDE (AOFL_PRODUCT, STUDENT_ID)\n",
    "# FROM base a\n",
    "# LEFT JOIN monthly_usage b USING (AOFL_PRODUCT,STUDENT_ID,MONTH)\n",
    "# LEFT JOIN monthly_skills c USING (AOFL_PRODUCT,STUDENT_ID,MONTH)\n",
    "# LEFT JOIN total_usage d USING (AOFL_PRODUCT,STUDENT_ID)\n",
    "# LEFT JOIN total_skills e USING (AOFL_PRODUCT,STUDENT_ID)\n",
    "# WHERE ORGANIZATION_NAME = 'Tucson Unified School District'\n",
    "# AND a.MONTH BETWEEN '2023-07-01' AND DATEADD(day, -1, DATE_TRUNC('month', CURRENT_DATE())) // Defined in the scope of the project\n",
    "# ORDER BY a.AOFL_PRODUCT, a.STUDENT_ID, a.MONTH;\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # older pivot code before the skills missing from month adjustment\n",
    "# import pandas as pd\n",
    "# import datetime\n",
    "\n",
    "# # Correctly renaming only the week columns, preserving key columns for the merge\n",
    "# key_columns = ['REGION_NAME','SCHOOL_NAME','CLASSROOM_NAME', 'STUDENT_ID','USER_ID','Perm ID','Last Name', 'First Name ', 'Name',\n",
    "#                'Grade', 'Gender','AOFL_PRODUCT', 'PLACEMENT_STATUS',\n",
    "#                'TOTAL_ACTIVE_WEEKS','TOTAL_USAGE_MINUTES','TOTAL_COMPLETED','TOTAL_COMPLETED_BYPASSED',\n",
    "#                'MIN_LOGIN_DATE','MAX_LOGIN_DATE'\n",
    "#                ]\n",
    "\n",
    "\n",
    "# # Pivot for weekly usage minutes\n",
    "# pivot_usage = df.pivot_table(index=key_columns,\n",
    "#                              columns='MONTH', \n",
    "#                              values='MONTHLY_USAGE_MINUTES',\n",
    "#                              aggfunc='sum',\n",
    "#                              fill_value=0).reset_index()\n",
    "\n",
    "# # pivot_usage.columns = [f'{col}_usage' if col not in key_columns and isinstance(col, str) else col for col in pivot_usage.columns]\n",
    "# pivot_usage.columns = [f'Minutes_{pd.to_datetime(col).strftime('%b%Y')}' if col not in key_columns and '-' in str(col) else col for col in pivot_usage.columns]\n",
    "\n",
    "# # Assuming you have skills data in the same DataFrame and a similar WEEK structure\n",
    "# pivot_skills = df.pivot_table(index=key_columns,\n",
    "#                               columns='MONTH', \n",
    "#                               values='COMPLETED_SKILLS',  # Adjust based on your actual column for weekly skills\n",
    "#                               aggfunc='sum',  # Adjust this based on how you want to aggregate skills data\n",
    "#                               fill_value=0).reset_index()\n",
    "\n",
    "# # pivot_skills.columns = [f'{col}_skills' if col not in key_columns and isinstance(col, str) else col for col in pivot_skills.columns]\n",
    "# pivot_skills.columns = [f'SkillsMastered_{pd.to_datetime(col).strftime('%b%Y')}' if col not in key_columns and '-' in str(col) else col for col in pivot_skills.columns]\n",
    "\n",
    "\n",
    "\n",
    "# # Merge the pivoted usage and skills tables on common identifiers\n",
    "# wide_df = pd.merge(pivot_usage, pivot_skills, \n",
    "#                    on=key_columns, \n",
    "#                    how='outer')\n",
    "\n",
    "# # Print the first few rows to verify the transformation\n",
    "# # wide_df.head()\n",
    "# wide_df.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
